services:
  nacos:
    image: hyperagi/nacos-client:last
    environment:
      - PUBLIC_IP=43.159.42.232
      - NODE=43.159.42.232:2
      - PORT=1082
      - WALLET_ADDRESS=0xaaC73e223DEc87218d849992b73B52be81910cAc
      - SERVICE_NAME=MFDoom/deepseek-r1-tool-calling:32b
    restart: always
  ollama:
    image: ollama/ollama
    ports:
      - '11434:11434'
    restart: always
    entrypoint: ['/bin/sh', '-c']
    runtime: nvidia
    command:
      - |
        ollama serve &
        sleep 5
        ollama pull cogito:32b
        ollama pull mxbai-embed-large
        wait
    volumes:
      - ./models:/root/.ollama/models
    environment:
      - OLLAMA_DEBUG=true
      - OLLAMA_LOG_LEVEL=trace
      - OLLAMA_VERBOSE=true
      - OLLAMA_KEEP_ALIVE=-1
      - OLLAMA_CONTEXT_LENGTH=8192
      - OLLAMA_NUM_PARALLEL=1
  poop-mcp-client:
    image: docker.hyperagi.network/poop-mcp-client:prod
    ports:
      - '8881:8881'
    restart: always
    environment:
      - ES_URI=http://43.159.42.232:9200
      - MODEL_NAME=cogito:32b
      - OLLAMA_BASE_URL=http://ollama:11434
      - MCP_SERVER=http://43.159.42.232:8888
      - HYPER_AGI_API=https://app.hyperagi.network/api
  frpc:
    image: snowdreamtech/frpc:0.62-bookworm
    volumes:
      - ./frpc/frpc.toml:/etc/frp/frpc.toml
